<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Running a Standard Evaluation Job :: Evaluating Model Accuracy with LM-Eval-Harness</title>
    <link rel="prev" href="section1.html">
    <link rel="next" href="section3.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Evaluating Model Accuracy with LM-Eval-Harness</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="llmops-lmeval" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Evaluating Model Accuracy with LM-Eval-Harness</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/index-lab-demo.html">Red Hat Demo Hub: Lab Environment Selection</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="mission.html">Mission Two</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Evaluating Model Accuracy with lm-eval-harness</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section1.html">Setting Up the Trusty AI Environment</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="section2.html">Running a Standard Evaluation Job</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section3.html">Interpreting Accuracy Results</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section4.html">Running a Domain-Specific Test</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section5.html">Course Wrap-up</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Evaluating Model Accuracy with LM-Eval-Harness</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Evaluating Model Accuracy with LM-Eval-Harness</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Evaluating Model Accuracy with LM-Eval-Harness</a></li>
    <li><a href="index.html">Evaluating Model Accuracy with lm-eval-harness</a></li>
    <li><a href="section2.html">Running a Standard Evaluation Job</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Running a Standard Evaluation Job</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>With the environment ready, we can now define and run our first evaluation. We will test our <code>granite-8b</code> model against the <strong>ARC Easy</strong> benchmark, a grade-school science reasoning test.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_1_configure_the_evaluation_job"><a class="anchor" href="#_2_1_configure_the_evaluation_job"></a>2.1 Configure the Evaluation Job</h3>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Clone the vLLM optimization repo.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">git clone https://github.com/redhat-ai-servicesetx-llm-optimization-and-inference-leveraging.git</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The evaluation is defined in a YAML file that specifies the <code>LMEvalJob</code> custom resource. The most important step is to point the job to your model&#8217;s inference endpoint.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Edit the <code>workshop_code/evals/trusty/arc_easy.yaml</code> file and update the <code>base_url</code> value with your model&#8217;s external inference URL.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">- name: base_url
      # the location of your model's /chat/completions or /completions endpoint
      value: https://&lt;YOUR_EXTERNAL_INFERENCE_ENDPOINT&gt;/v1/completions</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_2_2_create_and_run_the_job"><a class="anchor" href="#_2_2_create_and_run_the_job"></a>2.2 Create and Run the Job</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Apply the YAML file to your cluster to create the <code>LMEvalJob</code> resource. This will trigger Trusty AI to start a new evaluation pod.</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">oc apply -f workshop_code/evals/trusty/arc_easy.yaml -n vllm</code></pre>
</div>
</div>
</li>
<li>
<p>You can watch the progress of the evaluation by tailing the logs of the job pod. You will see progress reported in percentage points. This run will take approximately 10 minutes.</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">watch oc logs -f arc-easy-eval-job -n vllm</code></pre>
</div>
</div>
</li>
<li>
<p>Alternatively, you can watch the logs of your model&#8217;s predictor pod to see the actual questions being sent from the evaluation harness.</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console"># Find your exact pod name first
oc logs -f granite-8b-predictor-&lt;exact-pod-name&gt; -n vllm</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="section1.html">Setting Up the Trusty AI Environment</a></span>
  <span class="next"><a href="section3.html">Interpreting Accuracy Results</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
